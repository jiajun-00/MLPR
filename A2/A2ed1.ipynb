{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load('ct_data.npz')\n",
    "X_train = data['X_train']; X_val = data['X_val']; X_test = data['X_test']\n",
    "y_train = data['y_train']; y_val = data['y_val']; y_test = data['y_test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the mean of the training positions in y_train is zero? True\n",
      "The mean of the positions in y_val are: -0.2160085093241599\n",
      "The standard error of the positions in y_val are: 0.9814208579483531\n",
      "The mean of the first 5785 entries in the y_train is -0.44247687859693674\n",
      "The standard error of the first 5785 entries in the y_train is 0.907102593171408\n"
     ]
    }
   ],
   "source": [
    "print('Is the mean of the training positions in y_train is zero?', np.isclose(np.mean(y_train), 0))\n",
    "print('The mean of the positions in y_val are:', np.mean(y_val))\n",
    "print('The standard error of the positions in y_val are:', np.std(y_val))\n",
    "print('The mean of the first 5785 entries in the y_train is', np.mean(y_train[:5785]))\n",
    "print('The standard error of the first 5785 entries in the y_train is', np.std(y_train[:5785]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed constant columns: [59, 69, 179, 189, 351]\n",
      "Removed duplicate columns after first removing: [76, 77, 185, 195, 283, 354]\n"
     ]
    }
   ],
   "source": [
    "# Detect and remove constant columns\n",
    "constant_cols = np.where(np.all(X_train == X_train[0, :], axis=0))[0]\n",
    "\n",
    "# Remove constant columns\n",
    "X_train = np.delete(X_train, constant_cols, axis=1)\n",
    "X_val = np.delete(X_val, constant_cols, axis=1)\n",
    "X_test = np.delete(X_test, constant_cols, axis=1)\n",
    "\n",
    "\n",
    "print(\"Removed constant columns:\", constant_cols.tolist())\n",
    "\n",
    "# Detect and remove duplicate columns\n",
    "unique_cols, duplicate_cols = np.unique(X_train, axis=1, return_index=True)\n",
    "duplicate_cols = np.setdiff1d(np.arange(X_train.shape[1]), duplicate_cols)\n",
    "\n",
    "# Remove the columns\n",
    "X_train = np.delete(X_train, duplicate_cols, axis=1)\n",
    "X_val = np.delete(X_val, duplicate_cols, axis=1)\n",
    "X_test = np.delete(X_test, duplicate_cols, axis=1)\n",
    "\n",
    "\n",
    "print(\"Removed duplicate columns after first removing:\", duplicate_cols.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE of fit_linreg on train data is: 0.3567565397204054\n",
      "The RMSE of fit_linreg_gradopt on train data is: 0.3567556103401202\n",
      "The RMSE of fit_linreg on validation data is: 0.4230521968394695\n",
      "The RMSE of fit_linreg_gradopt on validation data is: 0.42305510586203865\n"
     ]
    }
   ],
   "source": [
    "from ct_support_code import *\n",
    "\n",
    "def fit_linreg(X, yy, alpha):\n",
    "    # add a column of ones to the end of X\n",
    "    X_fit = np.column_stack((X, np.ones(X.shape[0])))\n",
    "    # add the regularization term to the X matrix\n",
    "    alpha_matrix  = np.sqrt(alpha) * np.eye(X_fit.shape[1])\n",
    "    # we ignore the bias b in the regularization\n",
    "    alpha_matrix[-1, -1] = 0\n",
    "    # add the regularization term to the X matrix\n",
    "    X_hat = np.row_stack((X_fit, alpha_matrix))\n",
    "    # add zeros to the end of y with number of coefficients\n",
    "    y_hat = np.concatenate((y_train, np.zeros(X_fit.shape[1])))\n",
    "    # solve Xw = y with w = [w, b]\n",
    "    coeff = np.linalg.lstsq(X_hat, y_hat, rcond= None)[0] \n",
    "    b = coeff[-1]\n",
    "    w = coeff[:-1]\n",
    "    return w, b\n",
    "\n",
    "\n",
    "# the rmse\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(np.mean((y - y_pred)**2))\n",
    "\n",
    "# Linear regression with regularization\n",
    "w, b = fit_linreg(X_train, y_train, 30)\n",
    "\n",
    "\n",
    "y_train_pred_lg = np.dot(X_train, w) + b\n",
    "y_val_pred_lg = np.dot(X_val, w) + b\n",
    "\n",
    "# here we use support function fit_linreg_gradopt\n",
    "wg, bg = fit_linreg_gradopt(X_train, y_train, 30)\n",
    "\n",
    "y_train_pred_lgg = np.dot(X_train, wg) + bg\n",
    "y_val_pred_lgg = np.dot(X_val, wg) + bg\n",
    "\n",
    "print('The RMSE of fit_linreg on train data is:', rmse(y_train, y_train_pred_lg))\n",
    "print('The RMSE of fit_linreg_gradopt on train data is:', rmse(y_train, y_train_pred_lgg))\n",
    "print('The RMSE of fit_linreg on validation data is:', rmse(y_val, y_val_pred_lg))\n",
    "print('The RMSE of fit_linreg_gradopt on validation data is:', rmse(y_val, y_val_pred_lgg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on transformed training data: 0.15441185585977435\n",
      "RMSE on transformed validation data: 0.25424947251332386\n"
     ]
    }
   ],
   "source": [
    "def fit_logreg_gradopt(X, yy, alpha):\n",
    "    D = X.shape[1]\n",
    "    args = (X, yy, alpha)\n",
    "    init = (np.zeros(D), np.array(0))\n",
    "    ww, bb = minimize_list(logreg_cost, init, args)\n",
    "    return ww, bb\n",
    "\n",
    "K = 20 # number of thresholded classification problems to fit\n",
    "mx = np.max(y_train); mn = np.min(y_train); hh = (mx-mn)/(K+1)\n",
    "thresholds = np.linspace(mn+hh, mx-hh, num=K, endpoint=True)\n",
    "\n",
    "# Store probabilities for each model\n",
    "train_probs = np.zeros((X_train.shape[0], K))\n",
    "val_probs = np.zeros((X_val.shape[0], K))\n",
    "# record the ww and bb to V_3 and bk_3\n",
    "V_3 = np.zeros(( K,X_train.shape[1]))\n",
    "bk_3 = np.zeros(K)\n",
    "\n",
    "for kk in range(K):\n",
    "    labels = y_train > thresholds[kk]\n",
    "\n",
    "    ww, bb = fit_logreg_gradopt(X_train, labels, 30)\n",
    "    V_3[kk, :] = ww\n",
    "    bk_3[kk] = bb\n",
    "\n",
    "    # Preduct probabilities on the training and validation data\n",
    "    train_probs[:, kk] = 1 / (1 + np.exp(-np.dot(X_train, ww) - bb))\n",
    "    val_probs[:, kk] = 1 / (1 + np.exp(-np.dot(X_val, ww) - bb))\n",
    "\n",
    "# Fit regularized linear regression on the transformed dataset\n",
    "w_linear, b_linear = fit_linreg_gradopt(train_probs, y_train, alpha=30)\n",
    "\n",
    "# record w_linear and b_linear to ww_3 and bb_3\n",
    "ww_3 = w_linear\n",
    "bb_3 = b_linear\n",
    "\n",
    "# Calculate RMSE on the transformed training and validation sets\n",
    "train_predictions = np.dot(train_probs, w_linear) + b_linear\n",
    "val_predictions = np.dot(val_probs, w_linear) + b_linear\n",
    "\n",
    "train_rmse = np.sqrt(np.mean((train_predictions - y_train) ** 2))\n",
    "val_rmse = np.sqrt(np.mean((val_predictions - y_val) ** 2))\n",
    "\n",
    "print(\"RMSE on transformed training data:\", train_rmse)\n",
    "print(\"RMSE on transformed validation data:\", val_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on transformed training data with random initialization: 0.1392111516735692\n",
      "RMSE on transformed validation data with random initialization: 0.2718821406042969\n",
      "RMSE on transformed training data with Q3 parameters: 0.13956257348153217\n",
      "RMSE on transformed validation data with Q3 parameters: 0.2681698912659182\n",
      "RMSE on transformed test data with Q3 parameters: 0.3014994363080638\n"
     ]
    }
   ],
   "source": [
    "# fix the random seed\n",
    "np.random.seed(0)\n",
    "# set the hidden layers same to Q3\n",
    "K = 20\n",
    "D = X_train.shape[1]\n",
    "# a)a sensible random initialization of the parameters\n",
    "ww_init = np.random.randn(K)/np.sqrt(D+K)\n",
    "bb_init = np.array(0)\n",
    "V_init = np.random.randn(K, D)/np.sqrt(K+1)\n",
    "bk_init = np.zeros(K)\n",
    "init = (ww_init, bb_init, V_init, bk_init)\n",
    "\n",
    "def fit_nn_gradopt(X, yy, alpha, K, D, init):\n",
    "    args = (X, yy, alpha)\n",
    "    ww, bb, V, bk = minimize_list(nn_cost, init, args)\n",
    "    return ww, bb, V, bk\n",
    "\n",
    "# Fit a neural network with 20 hidden units\n",
    "ww, bb, V, bk = fit_nn_gradopt(X_train, y_train, 30, K, D, init)\n",
    "\n",
    "# Predict on the training and validation data\n",
    "y_train_pred_nn = nn_cost((ww, bb, V, bk), X_train)\n",
    "\n",
    "# Calculate RMSE on the transformed training sets\n",
    "train_rmse_nna = np.sqrt(np.mean((y_train_pred_nn - y_train) ** 2))\n",
    "print(\"RMSE on transformed training data with random initialization:\", train_rmse_nna)\n",
    "\n",
    "# Predict on the validation data\n",
    "y_val_pred_nn = nn_cost((ww, bb, V, bk), X_val)\n",
    "\n",
    "# Calculate RMSE on the transformed validation sets\n",
    "val_rmse_nna = np.sqrt(np.mean((y_val_pred_nn - y_val) ** 2))\n",
    "print(\"RMSE on transformed validation data with random initialization:\", val_rmse_nna)\n",
    "\n",
    "# b) the parameters initialized using the fits made in Q3.\n",
    "init = (ww_3, bb_3, V_3, bk_3)\n",
    "ww, bb, V, bk = fit_nn_gradopt(X_train, y_train, 30, K, D, init)\n",
    "\n",
    "# Predict on the training and validation data\n",
    "y_train_pred_nn = nn_cost((ww, bb, V, bk), X_train)\n",
    "\n",
    "# Calculate RMSE on the transformed training sets\n",
    "train_rmse_nnb = np.sqrt(np.mean((y_train_pred_nn - y_train) ** 2))\n",
    "print(\"RMSE on transformed training data with Q3 parameters:\", train_rmse_nnb)\n",
    "\n",
    "# Predict on the validation data\n",
    "y_val_pred_nn = nn_cost((ww, bb, V, bk), X_val)\n",
    "\n",
    "# Calculate RMSE on the transformed validation sets\n",
    "val_rmse_nnb = np.sqrt(np.mean((y_val_pred_nn - y_val) ** 2))\n",
    "print(\"RMSE on transformed validation data with Q3 parameters:\", val_rmse_nnb)\n",
    "\n",
    "# calculate the test data\n",
    "y_test_pred_nn = nn_cost((ww, bb, V, bk), X_test)\n",
    "\n",
    "# Calculate RMSE on the transformed test sets\n",
    "test_rmse_nnb = np.sqrt(np.mean((y_test_pred_nn - y_test) ** 2))\n",
    "print(\"RMSE on transformed test data with Q3 parameters:\", test_rmse_nnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum PI value in  1 iteration : 0.27484055761808257\n",
      "The maximum alpha in  1 iteration : 6.22\n",
      "The maximum PI value in  2 iteration : 0.18140627820261634\n",
      "The maximum alpha in  2 iteration : 2.2800000000000002\n",
      "The maximum PI value in  3 iteration : 0.13519171829121923\n",
      "The maximum alpha in  3 iteration : 10.4\n",
      "The maximum PI value in  4 iteration : 0.11539743542363978\n",
      "The maximum alpha in  4 iteration : 2.82\n",
      "The maximum PI value in  5 iteration : 0.16773646902592754\n",
      "The maximum alpha in  5 iteration : 2.84\n",
      "The best alpha is: 6.0\n",
      "The validation RMSE of the best alpha is: 0.24658887961477222\n",
      "RMSE on test data with the best alpha: 0.29067703512841714\n"
     ]
    }
   ],
   "source": [
    "# scipy.stats.norm.cdf\n",
    "from scipy.stats import norm\n",
    "\n",
    "def train_nn_reg(alpha):\n",
    "    K = 20\n",
    "    D = X_train.shape[1]\n",
    "    \n",
    "    ww_init = np.random.randn(K)/np.sqrt(D+K)\n",
    "    bb_init = np.array(0)\n",
    "    V_init = np.random.randn(K, D)/np.sqrt(K+1)\n",
    "    bk_init = np.zeros(K)\n",
    "    init = (ww_init, bb_init, V_init, bk_init)\n",
    "\n",
    "    # Fit a neural network with 20 hidden units\n",
    "    ww, bb, V, bk = fit_nn_gradopt(X_train, y_train, alpha, K, D, init)\n",
    "\n",
    "    # Predict on the validation data\n",
    "    y_val_pred_nn = nn_cost((ww, bb, V, bk), X_val)\n",
    "\n",
    "    # Calculate RMSE on the transformed validation sets\n",
    "    val_rmse_nn = np.sqrt(np.mean((y_val_pred_nn - y_val) ** 2))\n",
    "    return val_rmse_nn\n",
    "\n",
    "# alpha from 0 to 50 with step 0.02\n",
    "alphas = np.arange(0, 50, 0.02)\n",
    "\n",
    "# pick three alpha values to treat as training locations\n",
    "train_alphas = np.array([6, 25, 40])\n",
    "train_index = np.array([300, 1250, 2000])\n",
    "\n",
    "# use the remaining locations as values that you will consider with the acquisition function\n",
    "# remove the train_alphas from alphas\n",
    "alpha_acq = np.delete(alphas, train_index)\n",
    "\n",
    "# calculate y1, y2 and y3\n",
    "y1 = np.log(val_rmse_nna) - np.log(train_nn_reg(train_alphas[0]))\n",
    "y2 = np.log(val_rmse_nna) - np.log(train_nn_reg(train_alphas[1]))\n",
    "y3 = np.log(val_rmse_nna) - np.log(train_nn_reg(train_alphas[2])) \n",
    "\n",
    "yy = np.array([y1, y2, y3])\n",
    "\n",
    "def PI(mu, sd, y_obs):\n",
    "    return norm.cdf((mu - np.max(y_obs)) / sd)\n",
    "\n",
    "# iterate 5 times\n",
    "for i in range(1,6):\n",
    "\n",
    "    # find the posterior mean and variance\n",
    "    rest_cond_mu, rest_cond_cov = gp_post_par(alpha_acq, train_alphas, yy)\n",
    "\n",
    "    # find the standard deviation of each point\n",
    "    sd = np.sqrt(np.diag(rest_cond_cov))\n",
    "\n",
    "    # find the maximum value of PI\n",
    "    for j in range(len(alpha_acq)):\n",
    "        PI_val = PI(rest_cond_mu[j], sd[j], yy)\n",
    "        if j == 0:\n",
    "            max_PI = PI_val\n",
    "            max_alpha = alpha_acq[j]\n",
    "            max_index = j\n",
    "        elif PI_val > max_PI:\n",
    "            max_PI = PI_val\n",
    "            max_alpha = alpha_acq[j]\n",
    "            max_index = j\n",
    "    \n",
    "    print('The maximum PI value in ', str(i), 'iteration :', max_PI)\n",
    "    print('The maximum alpha in ', str(i), 'iteration :', max_alpha)\n",
    "\n",
    "    # add the max_alpha to train_alphas\n",
    "    train_alphas = np.append(train_alphas, max_alpha)\n",
    "    # remove the max_alpha from alpha_acq\n",
    "    alpha_acq = np.delete(alpha_acq, max_index)\n",
    "\n",
    "    # calculate the new y value\n",
    "    y_new = np.log(val_rmse_nna) - np.log(train_nn_reg(max_alpha))\n",
    "    yy = np.append(yy, y_new)\n",
    "\n",
    "# find the best alpha\n",
    "best_alpha = train_alphas[np.argmax(yy)]\n",
    "print('The best alpha is:', best_alpha)\n",
    "\n",
    "# find its validation RMSE\n",
    "best_val_rmse = train_nn_reg(best_alpha)\n",
    "print('The validation RMSE of the best alpha is:', best_val_rmse) \n",
    "\n",
    "# find the test RMSE\n",
    "K = 20\n",
    "D = X_train.shape[1]\n",
    "ww_init = np.random.randn(K)/np.sqrt(D+K)\n",
    "bb_init = np.array(0)\n",
    "V_init = np.random.randn(K, D)/np.sqrt(K+1)\n",
    "bk_init = np.zeros(K)\n",
    "init = (ww_init, bb_init, V_init, bk_init)\n",
    "\n",
    "\n",
    "# Fit a neural network with 20 hidden units\n",
    "ww, bb, V, bk = fit_nn_gradopt(X_train, y_train, best_alpha, K, D, init)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred_nn = nn_cost((ww, bb, V, bk), X_test)\n",
    "\n",
    "# Calculate RMSE on the test sets\n",
    "test_rmse = np.sqrt(np.mean((y_test_pred_nn - y_test) ** 2))\n",
    "print(\"RMSE on test data with the best alpha:\", test_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on transformed training data with random initialization: 0.025587545888610508\n",
      "RMSE on transformed validation data with random initialization: 0.21954907757778808\n",
      "RMSE on transformed test data with random initialization: 0.2349335232342645\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def nn_cost_new(params, X, yy=None, alpha=None):\n",
    "    # Unpack parameters from list\n",
    "    ww, bb, V, bk, M, bm, Q, bq = params\n",
    "\n",
    "    # Forwards computation of cost \n",
    "    L0 = np.dot(X, Q.T) + bq[None,:] # N,P\n",
    "    P0 = np.maximum(0, L0) # N,P\n",
    "    L1 = np.dot(P0, M.T) + bm[None,:] # N,M\n",
    "    P1 = np.maximum(0, L1) # N,M \n",
    "    L2 = np.dot(P1, V.T) + bk[None,:] # N,K\n",
    "    P2 = 1 / (1 + np.exp(-L2)) # N,K\n",
    "    F = np.dot(P2, ww) + bb # N,\n",
    "    if yy is None:\n",
    "        # user wants prediction rather than training signal:\n",
    "        return F\n",
    "    res = F - yy # N,\n",
    "    E = np.dot(res, res) + alpha*(np.sum(Q*Q)+ np.sum(M*M) + np.sum(V*V) + np.dot(ww,ww)) # 1x1\n",
    "\n",
    "    # Reverse computation of gradients\n",
    "    F_bar = 2*res # N,\n",
    "    ww_bar = np.dot(P2.T, F_bar) + 2*alpha*ww # K,\n",
    "    bb_bar = np.sum(F_bar) # scalar\n",
    "    P2_bar = np.dot(F_bar[:,None], ww[None,:]) # N,K\n",
    "    L2_bar = P2_bar * P2 * (1 - P2) # N,K\n",
    "    V_bar = np.dot(L2_bar.T, P1) + 2*alpha*V # K,D\n",
    "    bk_bar = np.sum(L2_bar, 0)\n",
    "    P1_bar = np.dot(L2_bar, V) # N,M\n",
    "    L1_bar = P1_bar * (L1 > 0) # N,M\n",
    "    M_bar = np.dot(L1_bar.T, P0) + 2*alpha*M # M,P\n",
    "    bm_bar = np.sum(L1_bar, 0)\n",
    "    P0_bar = np.dot(L1_bar, M) # N,P\n",
    "    L0_bar = P0_bar * (L0 > 0) # N,P\n",
    "    Q_bar = np.dot(L0_bar.T, X) + 2*alpha*Q # P,D\n",
    "\n",
    "\n",
    "    return E, (ww_bar, bb_bar, V_bar, bk_bar, M_bar, bm_bar, Q_bar, bq)\n",
    "\n",
    "# set the hidden layers same to Q3\n",
    "K = [128,64, 32]\n",
    "D = X_train.shape[1]\n",
    "# a)a sensible random initialization of the parameters\n",
    "ww_init = np.random.randn(K[2])/np.sqrt(1+K[2])\n",
    "#bb_init = np.random.randn()/np.sqrt(D+K)\n",
    "bb_init = np.array(0)\n",
    "\n",
    "V_init = np.random.randn(K[2], K[1])/np.sqrt(K[2]+K[1])\n",
    "bk_init = np.zeros(K[2])\n",
    "#bk_init = np.random.randn(K)/np.sqrt(K)\n",
    "M_init = np.random.randn(K[1], K[0])/np.sqrt(K[0]/2)\n",
    "bm_init = np.zeros(K[1])\n",
    "#bm_init = np.random.randn(D)/np.sqrt(D+1)\n",
    "Q_init = np.random.randn(K[0], D)/np.sqrt(D/2)\n",
    "bq_init = np.zeros(K[0])\n",
    "\n",
    "init = (ww_init, bb_init, V_init, bk_init, M_init, bm_init, Q_init, bq_init)\n",
    "\n",
    "def fit_nn_gradopt_new(X, yy, alpha, K, D, init):\n",
    "    args = (X, yy, alpha)\n",
    "    ww, bb, V, bk, M, bm, Q, bq = minimize_list(nn_cost_new, init, args)\n",
    "    return ww, bb, V, bk, M, bm, Q, bq\n",
    "\n",
    "# fit the model\n",
    "ww, bb, V, bk, M, bm, Q, bq = fit_nn_gradopt_new(X_train, y_train, 6.4, K, D, init)\n",
    "\n",
    "# Predict on the training set\n",
    "y_train_pred_nn = nn_cost_new((ww, bb, V, bk, M, bm, Q, bq), X_train)\n",
    "\n",
    "# Calculate RMSE on the transformed training sets\n",
    "train_rmse_nna = np.sqrt(np.mean((y_train_pred_nn - y_train) ** 2))\n",
    "print(\"RMSE on transformed training data with random initialization:\", train_rmse_nna)\n",
    "\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred_nn = nn_cost_new((ww, bb, V, bk, M, bm, Q, bq), X_val)\n",
    "\n",
    "# Calculate RMSE on the transformed validation sets\n",
    "val_rmse_nna = np.sqrt(np.mean((y_val_pred_nn - y_val) ** 2))\n",
    "print(\"RMSE on transformed validation data with random initialization:\", val_rmse_nna)\n",
    "\n",
    "# test on the test set\n",
    "y_test_pred_nn = nn_cost_new((ww, bb, V, bk, M, bm, Q, bq), X_test)\n",
    "\n",
    "# Calculate RMSE on the transformed test sets\n",
    "test_rmse_nna = np.sqrt(np.mean((y_test_pred_nn - y_test) ** 2))\n",
    "print(\"RMSE on transformed test data with random initialization:\", test_rmse_nna)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
